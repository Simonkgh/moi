<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Mine of Information - Trying Linux From Scratch (LFS)</title>
    <link rel="stylesheet" type="text/css" href="/assets/css/coderay.css">
    <link rel="stylesheet" type="text/css" href="/assets/css/stylesheet.css">
    <link type="application/atom+xml" title="Mine of Information" rel="alternate" href="/atom.xml"> 

    <meta name="generator" content="nanoc 4.12.15"> 
    <meta name="author" content="Simon Kitching"> 
  </head>
  <body>
    <section id="header">
      <span class='title'>The Mine of Information</span> <span class='desc'>(Nuggets of Programming and Linux)</span>
    </section>
    <div id="main">
      <section id='navpane'>
        <section>
  <ul id="navicons">
      <li class="nav">
      <a href="/" title="Home"><img src="/assets/images/Home.png"></a>
      <a href="/archives/" title="Archives"><img src="/assets/images/Calendar.png"></a>
      <a href="/site/welcome" title="E-Mail"><img src="/assets/images/Envelope.png"></a>
      <a href="/atom.xml" title="Subscribe Feed"><img src="/assets/images/RSS.png"></a>
      </li>
  </ul>
</section>

<section>
  <h1>About</h1>
  <ul id="about">
    <li>
      <a href="/site/welcome">Welcome</a>
    </li>
  </ul>
</section>

<section>
<h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/2023/12/monorepos/">Monorepos and Polyrepos</a>
      </li>
    
      <li class="post">
        <a href="/2023/12/httpapis/">HTTP APIs, REST APIs, and Others</a>
      </li>
    
      <li class="post">
        <a href="/2023/09/biden/">Biden on Democracy</a>
      </li>
    
      <li class="post">
        <a href="/2023/09/tech-breadth/">Maintaining Technical Depth</a>
      </li>
    
      <li class="post">
        <a href="/2023/08/vpns/">The Uselessness of Consumer VPNs</a>
      </li>
    
      <li class="post">
        <a href="/2023/06/microservices/">Some Aspects of Implementing Microservices..</a>
      </li>
    
      <li class="post">
        <a href="/2023/06/dtest-evolution-scrum-monad/">DDD, Architecture patterns, and More..</a>
      </li>
    
      <li class="post">
        <a href="/2023/05/testing/">Should Unit Tests Verify Requirements Only?</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>Categories</h1>
  <ul id="categories">
    
      <li class="catlink">
        <a href='/category/Architecture/'>Architecture</a>
      </li>
    
      <li class="catlink">
        <a href='/category/BigData/'>BigData</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Cloud/'>Cloud</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Cryptography/'>Cryptography</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Git/'>Git</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Infrastructure/'>Infrastructure</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Java/'>Java</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Links/'>Links</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Linux/'>Linux</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Network/'>Network</a>
      </li>
    
      <li class="catlink">
        <a href='/category/OSGi/'>OSGi</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Off-topic/'>Off-topic</a>
      </li>
    
      <li class="catlink">
        <a href='/category/OpenWRT/'>OpenWRT</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Programming/'>Programming</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Security/'>Security</a>
      </li>
    
      <li class="catlink">
        <a href='/category/Site/'>Site</a>
      </li>
    
  </ul>
</section>


      </section>
  
      <section id='content'>
        
  <div class='page'>
    <h1>Trying Linux From Scratch (LFS)</h1>
    <aside>First published on: August 30, 2015</aside>
    
    <article>
    <p>Categories: <a href='/category/Linux/'>Linux</a></p>
      <h1 id="intro">Intro</h1>

<p>The <a href="http://www.linuxfromscratch.org/">Linux From Scratch</a> site provides a tutorial on building a complete linux distribution “by hand”. I recently tried it; these are my notes.</p>

<p>The things you’re probably most curious about are:</p>

<ul>
  <li>time: how long does it take to do the LFS tutorial?</li>
  <li>quality: how well-written is the tutorial?</li>
  <li>learning: will I learn much about Linux from it?</li>
  <li>long-term: is the end result something I would actually use long-term?</li>
</ul>

<p>Short answers:</p>

<ul>
  <li>time: about 20 hours (ie 2.5 full working days - or possible on a single wet weekend for those without spouse and kids..)</li>
  <li>quality: the LFS book is very well written - some of the clearest technical instructions I have ever seen, and 100% error-free</li>
  <li>learning: well, yes I learned some things. But a lot of the time was spent copying/pasting from the instructions and waiting for compilation to finish</li>
  <li>long-term: I am still not sure if I will run the resulting system for a while, or go back to a “normal” distribution. Probably the latter - maintaining a self-built system is a lot of work.</li>
</ul>

<p>The result is a <strong>very basic</strong> system - no graphics, sound, wireless networking. All of that requires further work; there is a Beyond LFS (BLFS) book (also well written) with information on how to further extend the system, eg graphics, sound, wireless. I am currently installing some stuff from BLFS, and will write a separate article on that experience later.</p>

<p>Overall, the 2.5 days I spent were not wasted, but neither did I learn anything truly inspirational. Whether it is worth the time for <em>you</em> to work through LFS depends on your goals. I would suggest:</p>

<ul>
  <li>For those wanting to be “software packagers” (eg Debian maintainers), I think it provides useful insight into how a project is built overall.</li>
  <li>For those who expect to create customised Linux installations for embedded systems or similar, regularly work with cross-compilation, etc. then LFS is definitely worth-while.</li>
  <li>For those wanting to be linux admin gurus, probably not worthwhile - you will be working with redhat/debian/etc - spend the time getting to know those distros better instead</li>
  <li>For software developers, the time could probably be spent in more useful ways</li>
</ul>

<p>However even if you don’t want to complete the LFS tutorial, I would recommend reading some chapters:</p>

<ul>
  <li>the foreword</li>
  <li>the Package Management chapter (section 6.3 in edition 7.7 of the book). Note that the BLFS book strongly recommends “Symlink Style Package Management” using <code>make DESTDIR=... install</code>
</li>
  <li>the whole of chapter 7 (“Basic System Configuration”) is interesting.</li>
  <li>perhaps chapter 8 (“Making the LFS System Bootable”) which discusses kernel compilation and grub configuration</li>
</ul>

<p>Ch1-5 took me about 8 hours - this completes construction of all “temporary tools”, ie gets to the point where you can chroot to the new system. This is an important step, as it is then possible to run an entire userspace without using any code from the host (chroot). However these temporary tools have internal dependencies on a temporary “/tools” directory which <em>can</em> be made to work but is not good long-term. The next step is therefore to chroot to the new system and rebuilt everything again with <em>proper</em> paths. I learned a few things here about cross-compilation, chroot, etc.</p>

<p>Ch6 also took me about 8 hours - completes the recompilation of all core software. Rather tedious and not very interesting.</p>

<p>Ch7-9 took just a couple of hours, and was very interesting.</p>

<p>The above durations include some time spent reading interesting documents referenced from the LFS book such as manpages, the Filesystem Hierarchy Standard, and the user-based package manager documentation.</p>

<p>The ALFS (automated linux from scratch) project might be worth trying out; the instructions in the book are marked up in a way that makes it possible for ALFS to <em>extract and execute them</em>. This both (a) ensures that the book is 100% correct, and (b) avoids much tedium. Given that Ch6 takes so much time and offers so little to learn, I would suggest investigating whether ALFS can be applied at least to that part.</p>

<p>Note that I used the systemd-based variant of the book.</p>

<h1 id="things-that-could-be-better-explained">Things that could be better explained</h1>

<p>The following items are things that confused me at first. Most are actually explained if you read the LFS book carefully, or at least are <em>eventually</em> explained. However it might be useful to know these up-front before starting.</p>

<p>Those who know more about Linux than I might not consider some points below to be “real problems”. Those with less knowledge might not realize there are problems at all…</p>

<h2 id="the-problem-with-gcc-and-file-paths">The problem with GCC and file paths</h2>

<p><a href="http://landley.net/hg/aboriginal/file/be48c60f9edb/design.html#l288">According to Rob Landley</a> the gnu toolchain (gcc/binutils/etc) is a very poor cross-compiler; it is “full of hardwired assumptions .. such as the C library, header paths”. This is why LFS has such a complicated “pass1”, and includes steps that use <em>sed</em> to manually change paths within <em>generated binaries</em>! Maybe using llvm would improve this?</p>

<p>Many compiled applications have “search paths” hard-wired into their code. In particular, the GNU linker and compiler search for files using default paths encoded into the binaries.  The tutorial creates a directory <code>/tools</code> in the host, and “first-pass” (temporary) binaries are compiled for the new LFS system using this directory as the “search path”. It took me a while to realize that the point of this is that after using <code>chroot()</code> to switch to a new environment, the path <code>/tools</code> still works, and contains the same files. Everything compiled under the host-root using ‘/tools’ is eventually recompiled under the lfs-root (ie using chroot) without the temp <code>/tools</code> path, after which the <code>/tools</code> directory can then be removed.</p>

<h2 id="root-or-not-root">Root or not Root</h2>

<p>Commands in the first few chapters of the tutorial need to be run as <code>root</code>. Later, actual compilation of the code is done as a normal user - which is sensible; unfortunately that isn’t mentioned until section 4.3.</p>

<p>I would recommend the “wget” operations (early in the tutorial) be run as a normal user, rather than using root (which the tutorial assumes).</p>

<h2 id="saving-the-intermediate-state">Saving the intermediate state</h2>

<p>The steps in chapter-5 (“first pass”) produce a “cross-compilation” environment that can be reused. You can save this state, and then use it many times. It can be used to compile <em>different versions</em> of the software; although the LFS tutorial recompiles exactly the same set of source-packages again, that doesn’t need to be the case. In particular, when “core” software changes versions (eg glibc) then it is recommended to return to this “cross-compilation” environment and recompile everything in LFS (ie repeat chapter 6 but with newer sourcecode).</p>

<h2 id="the---prefix-parameter">The –prefix parameter</h2>

<p>A “–prefix=/usr” parameter is passed to most makefiles, but it is not explained why. The reason is to override the default prefix of <code>/usr/local</code>. Many packages default to installing in “/usr/local” which is sensible as they are assuming you are running a typical “packaged” distribution (eg redhat/debian) and so should not mix locally-compiled binaries with package-managed binaries. This is not the case for LFS, so overriding prefix is usually required.</p>

<h2 id="the-expected-build-and-test-output">The “expected” build and test output</h2>

<p>The LFS site provides example output of build and test steps, which is very useful. The link is given in section 4.6 “About The Test Suites”, but I kept forgetting it. For reference, the output for the LFS version I was using could be found at:</p>

<ul>
  <li><a href="http://www.linuxfromscratch.org/lfs/build-logs/7.7-systemd/">http://www.linuxfromscratch.org/lfs/build-logs/7.7-systemd/</a></li>
</ul>

<h2 id="interrupting-and-resuming-lfs">Interrupting and Resuming LFS</h2>

<p>When resuming work after rebooting do the following (as noted in section 6.4):</p>

<pre><code># Section 6.2.2: mounting and populating /dev
mount -v --bind /dev $LFS/dev

# Section 6.2.3 Mounting virtual Kernel File Systems
mount -vt devpts devpts $LFS/dev/pts -o gid=5,mode=620
mount -vt proc proc $LFS/proc
mount -vt sysfs sysfs $LFS/sys
mount -vt tmpfs tmpfs $LFS/run

# Section 6.4 Chroot
chroot "$LFS" /tools/bin/env -i \
    HOME=/root                  \
    TERM="$TERM"                \
    PS1='\u:\w\$ '              \
    PATH=/bin:/usr/bin:/sbin:/usr/sbin:/tools/bin \
    /tools/bin/bash --login +h

# If you've completed 6.36 (recompile bash) then do this (or use /bin/bash in the step above): see 6.72
exec /bin/bash --login +h
</code></pre>

<h2 id="section-72-networking">Section 7.2 Networking</h2>

<p>This chapter could do with some restructuring and extended explanations.</p>

<h2 id="section-831--building-kernel">Section 8.3.1 : building kernel</h2>

<p>The first “note” shows an image of a config program, but does not mention that “make menuconfig” is the way to get that menu until <em>after</em> the table.</p>

<h2 id="section-84-configuring-grub">Section 8.4: configuring GRUB</h2>

<p>How about adding instructions to create a bootable USB stick (rather than just a CD)?</p>

<p>And how about instructions to add a grub menu to the grub.cfg of the “host” operating system? Running “update-grub2” on my debian8 host system auto-detected the kernel on the LFS partition and added a menu option - much safer than running <code>grub-install</code> in the LFS chroot.</p>

<h2 id="links-to-tdlp-the-linux-documentation-project">Links to TDLP (The Linux Documentation Project)</h2>

<p>The LFS book has a number of links to documentation on the TLDP website. Sadly, everything on TLDP is completely out-dated, and should be ignored. LFS should really remove such links, as the referenced documents are no longer helpful.</p>

<p>In particular, the “Prerequisites” section recommends reading a TDLP “Software-Building-HOWTO” document. This is <em>really</em> out-of-date (Motif?! “a.out”?! Imake?!), and has many broken links. I’ve created <a href="/linux/beginners-installing-from-source">a document</a> that covers similar topics but without the outdated references.</p>

<p>TLDP was a great idea, but sadly has not functioned long-term.</p>

<h2 id="issues-tracker">Issues Tracker</h2>

<p>The book refers to an LFS “issues tracker”, in particular that suggested changes to the book should be made by opening a ticket. However the issue-tracker is almost impossible to find. The home page has no link to it, nor do the “support”, “contribute” or “site map” subpages. The <a href="http://www.linuxfromscratch.org/lfs">LFS Book page</a> does have a “Report a Bug” link in the menu, but that leads nowhere relevant.</p>

<p>Only after going to the wiki, then to the LFS component of the wiki, did I find a “View Tickets” option in the top menubar.</p>

<p>Actually, LFS uses “Trac” which is both a wiki <em>and</em> a bugtracker. So in effect, the wiki <em>is</em> the bugtracker - hence the “View Tickets” option in the wiki menubar.</p>

<p>While on the subject of the wiki, it isn’t used in the manner many other projects use their wikis for. There is very little “community content” here; instead it is mainly used by the LFS maintainers. There is nevertheless some useful information here.</p>

<h2 id="package-managers">Package Managers</h2>

<p>Although the LFS tutorial installs everything without using a package-manager, it is possible to install a package-manager on LFS if you wish. There is a section in the LFS book about this, although it doesn’t really <em>recommend</em> any particular option. Nevertheless when reading the BLFS book and the email lists, it appears that many LFSers use the “DESTDIR” approach as documented in LFS. It is probably not worth using this for the <em>basic</em> software in the LFS book itself, but well worth considering before installing anything from BLFS.</p>

<p>The options discussed in the LFS book are all rather unusual for people (like me) used to mainstream distributions such as Debian, Ubuntu or Fedora. Most of the options discussed in LFS could be named “package loggers” rather than “package managers”, ie they just track what was installed and when.</p>

<p>It is theoretically possible to install rpm or dpkg on LFS, but you’d be pretty alone - the LFSers generally like the bare-bones approach.</p>

<p>One person has documented how to <a href="http://www.linuxfromscratch.org/hints/downloads/files/dpkg.txt">install the Debian apt and dpkg</a> tools on LFS, if you are really determined to do so. It might be a good way to get familiar with dpkg/apt..</p>

<p>And of course <a href="http://www.linuxfromscratch.org/hints/downloads/files/rpm.txt">installing rpm</a> on LFS has also been documented.</p>

<h2 id="section-52-target-triple">Section 5.2: Target Triple</h2>

<p>The “target triple” bit has me confused. Running config.guess from binutils gave <code>x86_64-unknown-linux-gnu</code>.</p>

<p>The <a href="https://www.gnu.org/software/autoconf/manual/autoconf-2.65/html_node/Specifying-Target-Triplets.html">autoconf manual: Target Triplets</a> and linked page <a href="https://www.gnu.org/software/autoconf/manual/autoconf-2.65/html_node/System-Type.html#System-Type">System Type</a> have a reasonable description. From this, I could decode the output of config.guess for my machine as:</p>

<ul>
  <li>cpu: x86_64</li>
  <li>company: unknown</li>
  <li>system (divided into kernel-os): linux-gnu</li>
</ul>

<p>I have no idea what a compiler would do with the “company” string. I <em>think</em> that “system” here indicates the convention used for making syscalls and function-calls on this platform (ie which registers are used, who cleans up the stack, etc), but am not 100% certain.</p>

<h2 id="section-53-shell">Section 5.3: shell</h2>

<p>5.3 states that “/bin/sh” must be a symlink to bash. However on my system (deb8) it is a link to dash. There were no hints on how to <em>elegantly</em> resolve this, other than rewiring sh for my entire system (which I did, but reluctantly).</p>

<p>Note in particular, that commands such as <code>cp -uv $file{,.orig}</code> are used extensively, and this braces-format is a bash extension that will not work with dash.</p>

<h2 id="section-621-dev">Section 6.2.1: /dev</h2>

<p>I was a bit puzzled why <code>dev/console</code> and <code>dev/null</code> were created when the host <code>/dev</code> was then mounted on top of it anyway. And after rebooting, devtmpfs will be mounted on <code>/dev</code>. So when would these files ever be used?</p>

<h2 id="section-623-devpts">Section 6.2.3: devpts</h2>

<p>I would have appreciated a bit more background on ‘devpts`. This link provides at least some information:</p>

<ul>
  <li><a href="http://unix.stackexchange.com/questions/93531/what-is-stored-in-dev-pts-files-and-can-we-open-them">http://unix.stackexchange.com/questions/93531/what-is-stored-in-dev-pts-files-and-can-we-open-them</a></li>
</ul>

<h2 id="section-633--relative-files">Section 6.3.3 : relative files</h2>

<p>Don’t understand. Why would a system have “files that depend on the position of files on a disk system”?</p>

<h2 id="glibc-and-ncsd">GLIBC and NCSD</h2>

<p>An “/etc/nscd.conf” (name service cache daemon) provided by glibc. What does it do?</p>

<ul>
  <li>related to systemd “nscd.service” unit file =&gt; /usr/sbin/ncsd</li>
  <li>daemon appears to depend on passwd,group,hosts,services,netgroup</li>
  <li>it is a daemon that maintains a cross-user cache of “lookup info” of various sorts, including hostnames.</li>
  <li>glibc calls that look up such information query the daemon (if it is available) for performance reasons</li>
</ul>

<p>Glibc functions which use the daemon include:</p>

<ul>
  <li>getgrgid, getgrname -&gt; get group info by id or name</li>
  <li>gethostbyname, gethostbyaddr -&gt; get host info</li>
  <li>getservbyname, getservbyport -&gt; get service info by name or port</li>
</ul>

<p>Actually, glibc provides more than just a library. Interesting things include:</p>

<ul>
  <li>locale, tzselect, zic – timezone stuff</li>
  <li>nscd – caching daemon</li>
  <li>catchsegv (prints stacktrace for apps that terminate with segfault)</li>
  <li>libc – the “primary” output</li>
  <li>libcrypt – cryptography library</li>
  <li>libmcheck – memory allocation checking</li>
  <li>libpthread – posix threads</li>
</ul>

<h2 id="section-6171">Section 6.17.1</h2>

<p>Why are links created like “<code>ln -sv ../usr/bin/cpp /lib</code>” rather than “<code>ln -sv /usr/bin/cpp</code>”? They are effectively the same, but isn’t an absolute path easier?</p>

<h1 id="other-notes">Other Notes</h1>

<h2 id="mount-point-leakage">mount-point leakage</h2>

<p>Although the compilation in chapter 6 is intended to rid all binaries of traces of the host operating system, it appears that the applications generated by the e2fsprogs package get the <em>mount point</em> of the chroot filesystem embedded into them - ie the path in the host. Don’t worry about this; this path is only present in <em>debug entries</em> and will disappear if <code>/tools/bin/strip</code> is run on the apps (as recommended in section 6.??).</p>

<h2 id="downloading-lfs-files">Downloading LFS Files</h2>

<p>There are some security issues regarding downloading files - at least LFS doesn’t follow good security practice IMO. Section3.1 recommends checking the downloaded files against an “md5sums” file. However in the downloaded HTML book version, the link is to a file included in the original download. A hacked book could provide a hacked md5sums file. The <a href="http://www.linuxfromscratch.org/lfs/downloads/stable-systemd/">original directory</a> I downloaded from has the same md5sums file - but that dir is “http” not “https” so content can easily be manipulated via a man-in-the-middle. All unlikely, but perhaps LFS should be a good example of best-practice? - and LFS is <em>mirrored</em>, which means a compromised mirror could do significant damage.</p>

<p>As noted earlier, LFS also recommends running wget as <em>root</em> when downloading the initial set of software. This doesn’t feel like a good idea to me.</p>

<h2 id="compiling-glibc">Compiling glibc</h2>

<p>When running <code>glibc make check</code> the test <code>ntpl/tst-robust8</code> failed for me, although the “example test output” showed it works. I continued anyway, and haven’t noticed any problems yet.</p>

<h2 id="section-628-e2fsprogs-without-swapspace">Section 6.28: e2fsprogs without swapspace</h2>

<p>In e2fs “make check”, test “ss” fails: “Regression test for ss library failed!” Presumably this happens when (like me) no swap-space is configured (I have 16GB ram, no need for swap).</p>

<h2 id="section-649-gettext">Section 6.49 Gettext</h2>

<p>Compilation failed on the first pass: makefile variable “dependency_dirs” somehow got set to the <em>mount point</em> of the chroot-filesystem. I recompiled libtool (thinking this might have something to do with it), then recompiled gettext and it worked. Not sure if the libtool rebuild actually did anything, or whether a simple rebuild of gettext would have worked anyway…</p>

<p>Or maybe I screwed up the “–prefix” entry?</p>

<p>Note also that e2fsprogs encodes the <em>mount point</em> of the chroot-filesystem into its binaries, which confused me at first. However these are just debug symbols that get stripped later.</p>

<h2 id="section-661-compiling-make">Section 6.61: compiling Make</h2>

<p>“make check” failed one test consistently.</p>

<pre><code>misc/fopen-fail ......................................... 
Test timed out after 5 seconds
Error running /sources/make-4.1/tests/../make (expected 512; got 14): /sources/make-4.1/tests/../make -f work/misc/fopen-fail.mk

Caught signal 14!
FAILED (0/1 passed)
</code></pre>

<p>The error-log in “tests/work/misc/fopen-fail.mk” says <code>*** Too many open files.  Stop.</code> However the open-file-limit seems adequate:</p>

<pre><code>root:/sources/make-4.1/tests/work# cat /proc/sys/fs/file-max
1605663

root:/sources/make-4.1/tests/work# ulimit -Hn
65536
</code></pre>

<h2 id="section-73-device-and-module-handling">Section 7.3 Device and Module Handling</h2>

<p>In general, great info - including useful background.</p>

<p>In 7.3.2.2, suggested minor changes:</p>

<p>“Device files are created by the kernel by the devtmpfs..” -&gt; “Device files are created automatically by the kernel in the devtmpfs when a driver allocates (major,minor) device numbers. The created file is always owned by root, has mode 0600, and the name of some devices varies depending upon order of discovery” (see 7.3.3.7 and 7.4.1).</p>

<p>A “uevent” is a specially-formatted string sent by the kernel to a netlink socket; the string contains the id of the corresponding sysfs node which provides further information about that device. The <code>udev</code> program is expected to listen on this netlink socket.</p>

<p>udev can maintain a persistent mapping of (device,name) in order to provide “stable names” for devices such as network-cards (which may be discovered in different orders on different boots) or usb-sticks (which should be assigned the same name regardless of which port they are connected to).</p>

<p>Warning: the symlink approach currently has problems with suspend/resume: when an app has opened a device via a symlink, it holds a filehandle that refers to the <em>symlink target</em>. On resume, devices are re-enumerated resulting in devices potentially being allocated different names. udev will then recreate the “stable-named” symlinks pointing to different targets. An app opening the “stable symlink name” would therefore connect to the correct device - but the open filehandle now points to a <em>different</em> device!</p>

<h1 id="time-required-to-build">Time Required to Build</h1>

<p>One SBU (standard build unit) = 2 minutes on my laptop.  Compiling GCC first pass took 12 minutes =&gt; 6 SBU.  The slowest project by far is gcc : 63 SBU according to the docs which worked about approximately correct - 2hrs on my reasonably fast laptop with SSD</p>

<p>When building “from scratch” the problem is that compiling binutils source requires a compiler - but the compiler requires binutils. The solution is to build a temporary binutils with the host compiler, then build a temporary gcc with the custom binutils, then build a final binutils with the temporary compiler and temporary binutils, then build a final gcc with the temporary gcc and final binutils. Phew!</p>

<h1 id="minor-points">Minor points</h1>

<p>I learnt that <code>addr2line</code> (from binutils) can map a program address back to sourcecode file/line (requires debug-info). Useful for crashing apps! (see also catchsegv)</p>

    </article>
  </div>
    
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_shortname = 'mineofinformation'; // mineofinformation (disqus site id)
      var disqus_pageid = '/linux/linux-from-scratch/'; // /relative/path/to/article/dir

      var disqus_config = function () {
        this.page.identifier = disqus_pageid;
        this.page.url = 'https://moi.vonos.net' + disqus_pageid;
      };
      (function() {
        var d = document, s = d.createElement('script');
        s.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
  



      </section>
    </div>
    <section id="footer">
      <p>Copyright &copy; 2025 - Simon Kitching</p>
    </section>
  </body>
</html>

